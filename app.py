# app.py
# CogCompass: AI ì—°êµ¬ ë„¤ë¹„ê²Œì´í„°(ì¸ì§€ì‹¬ë¦¬í•™)
# - Single-file Streamlit app
# - Sidebar: OpenAI API Key, local JSON persistence toggle
# - Core: research topic generator, trending paper fetch + LLM summaries, idea expansion + actionable next steps

import os
import re
import json
import time
import math
import uuid
import textwrap
import datetime as dt
from typing import Any, Dict, List, Optional, Tuple

import requests
import streamlit as st

# -----------------------------
# Page config
# -----------------------------
st.set_page_config(
    page_title="CogCompass: AI ì—°êµ¬ ë„¤ë¹„ê²Œì´í„°",
    page_icon="ğŸ§ ",
    layout="wide",
)

# -----------------------------
# Style (readability-first)
# -----------------------------
CUSTOM_CSS = """
<style>
/* Improve readability */
html, body, [class*="css"]  {
  font-family: system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, "Apple SD Gothic Neo", "Noto Sans KR", "Malgun Gothic", sans-serif;
}
.block-container { padding-top: 1.2rem; padding-bottom: 2.5rem; }
h1, h2, h3 { letter-spacing: -0.02em; }
.small-muted { color: rgba(49, 51, 63, 0.7); font-size: 0.92rem; }
.badge {
  display:inline-block; padding:0.18rem 0.52rem; border-radius:999px;
  background: rgba(14, 17, 23, 0.06); margin-right:0.35rem; font-size:0.86rem;
}
.card {
  border: 1px solid rgba(49, 51, 63, 0.18);
  border-radius: 14px;
  padding: 14px 14px 10px 14px;
  background: rgba(255,255,255,0.6);
}
hr { margin: 0.8rem 0; }
code { font-size: 0.92em; }
</style>
"""
st.markdown(CUSTOM_CSS, unsafe_allow_html=True)


# -----------------------------
# Persistence
# -----------------------------
DEFAULT_STORE_PATH = "cogcompass_store.json"

def _now_iso() -> str:
    return dt.datetime.now().isoformat(timespec="seconds")

def safe_read_json(path: str) -> Dict[str, Any]:
    if not os.path.exists(path):
        return {}
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return {}

def safe_write_json(path: str, data: Dict[str, Any]) -> None:
    tmp = path + ".tmp"
    with open(tmp, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    os.replace(tmp, path)

def load_store(use_local: bool, path: str) -> Dict[str, Any]:
    if use_local:
        data = safe_read_json(path)
        return data if isinstance(data, dict) else {}
    # session store
    return st.session_state.get("store", {})

def save_store(use_local: bool, path: str, store: Dict[str, Any]) -> None:
    if use_local:
        safe_write_json(path, store)
    else:
        st.session_state["store"] = store

def ensure_store_schema(store: Dict[str, Any]) -> Dict[str, Any]:
    store = store or {}
    store.setdefault("created_at", _now_iso())
    store.setdefault("updated_at", _now_iso())
    store.setdefault("topics", [])       # generated topics
    store.setdefault("papers", [])       # fetched papers + summaries
    store.setdefault("notes", [])        # user notes
    store.setdefault("favorites", {"topics": [], "papers": []})
    return store


# -----------------------------
# OpenAI client (supports both new & legacy)
# -----------------------------
def openai_chat_completion(
    api_key: str,
    model: str,
    messages: List[Dict[str, str]],
    temperature: float = 0.5,
    max_tokens: int = 900,
) -> str:
    """
    Returns assistant text.
    Tries OpenAI v1 SDK; falls back to REST if needed.
    """
    if not api_key:
        raise ValueError("OpenAI API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤.")

    # Prefer new SDK if available
    try:
        from openai import OpenAI  # type: ignore
        client = OpenAI(api_key=api_key)
        resp = client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens,
        )
        return (resp.choices[0].message.content or "").strip()
    except Exception:
        # REST fallback
        url = "https://api.openai.com/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json",
        }
        payload = {
            "model": model,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens,
        }
        r = requests.post(url, headers=headers, json=payload, timeout=60)
        if r.status_code >= 400:
            raise RuntimeError(f"OpenAI API ì˜¤ë¥˜: {r.status_code} / {r.text[:300]}")
        data = r.json()
        return (data["choices"][0]["message"]["content"] or "").strip()


# -----------------------------
# External paper sources (no key)
# -----------------------------
SEMANTIC_SCHOLAR_API = "https://api.semanticscholar.org/graph/v1"
ARXIV_API = "http://export.arxiv.org/api/query"

def _clean_text(s: str) -> str:
    s = re.sub(r"\s+", " ", s or "").strip()
    return s

@st.cache_data(show_spinner=False, ttl=60 * 60)
def fetch_semantic_scholar_papers(
    query: str,
    limit: int = 10,
    year_from: Optional[int] = None,
    year_to: Optional[int] = None,
    sort: str = "citationCount",  # citationCount | publicationDate
) -> List[Dict[str, Any]]:
    """
    Semantic Scholar Paper Search.
    """
    if not query.strip():
        return []

    params = {
        "query": query,
        "limit": min(max(limit, 1), 40),
        "fields": "title,abstract,year,authors,venue,citationCount,publicationDate,url,externalIds,isOpenAccess,openAccessPdf",
        "offset": 0,
        "sort": sort,
    }
    # year filter: Semantic Scholar supports year in query syntax. We apply query decoration.
    q = query.strip()
    if year_from and year_to:
        q = f"{q} year:{year_from}-{year_to}"
    elif year_from:
        q = f"{q} year:{year_from}-"
    elif year_to:
        q = f"{q} year:-{year_to}"
    params["query"] = q

    url = f"{SEMANTIC_SCHOLAR_API}/paper/search"
    r = requests.get(url, params=params, timeout=30)
    if r.status_code >= 400:
        return []
    data = r.json()
    out = []
    for p in data.get("data", []) or []:
        out.append({
            "source": "SemanticScholar",
            "paperId": p.get("paperId"),
            "title": _clean_text(p.get("title", "")),
            "abstract": _clean_text(p.get("abstract", "")),
            "year": p.get("year"),
            "publicationDate": p.get("publicationDate"),
            "authors": [a.get("name") for a in (p.get("authors") or []) if a.get("name")],
            "venue": p.get("venue"),
            "citationCount": p.get("citationCount"),
            "url": p.get("url"),
            "isOpenAccess": p.get("isOpenAccess"),
            "openAccessPdf": (p.get("openAccessPdf") or {}).get("url"),
            "externalIds": p.get("externalIds") or {},
        })
    return out

@st.cache_data(show_spinner=False, ttl=60 * 60)
def fetch_arxiv_papers(
    query: str,
    limit: int = 10,
    sortBy: str = "submittedDate",  # relevance | submittedDate | lastUpdatedDate
    sortOrder: str = "descending",
) -> List[Dict[str, Any]]:
    """
    arXiv API (ATOM). Light parsing without external libs.
    """
    if not query.strip():
        return []

    # arXiv query: wrap keywords
    q = "all:" + " AND all:".join([re.sub(r"[^\w\-]+", " ", t).strip() for t in query.split() if t.strip()])
    params = {
        "search_query": q,
        "start": 0,
        "max_results": min(max(limit, 1), 40),
        "sortBy": sortBy,
        "sortOrder": sortOrder,
    }
    r = requests.get(ARXIV_API, params=params, timeout=30)
    if r.status_code >= 400:
        return []
    xml = r.text

    # Minimal ATOM parsing using regex (good enough for a Streamlit MVP)
    entries = re.split(r"<entry>", xml)[1:]
    out = []
    for e in entries:
        title = re.search(r"<title>(.*?)</title>", e, re.S)
        summary = re.search(r"<summary>(.*?)</summary>", e, re.S)
        published = re.search(r"<published>(.*?)</published>", e, re.S)
        link = re.search(r"<id>(.*?)</id>", e, re.S)
        authors = re.findall(r"<name>(.*?)</name>", e, re.S)

        t = _clean_text(title.group(1)) if title else ""
        s = _clean_text(summary.group(1)) if summary else ""
        pub = _clean_text(published.group(1)) if published else ""
        u = _clean_text(link.group(1)) if link else ""
        out.append({
            "source": "arXiv",
            "paperId": None,
            "title": t,
            "abstract": s,
            "year": int(pub[:4]) if len(pub) >= 4 and pub[:4].isdigit() else None,
            "publicationDate": pub,
            "authors": [_clean_text(a) for a in authors if _clean_text(a)],
            "venue": "arXiv",
            "citationCount": None,
            "url": u,
            "isOpenAccess": True,
            "openAccessPdf": u.replace("/abs/", "/pdf/") + ".pdf" if "/abs/" in u else None,
            "externalIds": {},
        })
    return out


# -----------------------------
# LLM prompt helpers (philosophy: actionable)
# -----------------------------
SYSTEM_CORE = """ë„ˆëŠ” 'CogCompass: AI ì—°êµ¬ ë„¤ë¹„ê²Œì´í„°(ì¸ì§€ì‹¬ë¦¬í•™)'ì˜ ì—°êµ¬ ì½”íŒŒì¼ëŸ¿ì´ë‹¤.
ì‚¬ìš©ìì—ê²Œ 'ë¬´ì—‡ì„ í•´ì•¼ í•˜ëŠ”ì§€'ê°€ ë°”ë¡œ ë³´ì´ë„ë¡, í•­ìƒ ì‹¤í–‰ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì œì•ˆí•œë‹¤.
ê¸ˆì§€: ì¶”ìƒì  ì¡°ì–¸ë§Œ í•˜ê¸°, ë»”í•œ êµê³¼ì„œì‹ ì„¤ëª…, ê³¼í•œ ì¥í™©í•¨.
í•„ìˆ˜: (1) êµ¬ì²´ ì—°êµ¬ì§ˆë¬¸/ê°€ì„¤ (2) ìµœì†Œ ì‹¤í–‰ ì‹¤í—˜/ë¶„ì„ ê³„íš (3) í•„ìš”í•œ ë°ì´í„°/ìê·¹/ì¸¡ì • (4) ë¦¬ìŠ¤í¬/ëŒ€ì•ˆ (5) ë‹¤ìŒ 7ì¼ TODOë¥¼ í¬í•¨í•´ë¼.
ì¶œë ¥ì€ í•œêµ­ì–´ë¡œ, êµ¬ì¡°í™”ëœ ë¶ˆë¦¿/ì„¹ì…˜ìœ¼ë¡œ ê°„ê²°íˆ ì‘ì„±í•œë‹¤.
"""

def build_topic_prompt(
    user_context: str,
    focus: str,
    methods: List[str],
    constraints: str,
    n: int,
) -> List[Dict[str, str]]:
    method_str = ", ".join(methods) if methods else "ì œì•½ ì—†ìŒ"
    user_context = user_context.strip()
    constraints = constraints.strip()

    u = f"""
[ì‚¬ìš©ì ë§¥ë½]
{user_context if user_context else "ì—†ìŒ"}

[ê´€ì‹¬ ì´ˆì ]
{focus}

[ì„ í˜¸ ë°©ë²•ë¡ /ë°ì´í„°]
{method_str}

[ì œì•½/í˜„ì‹¤ ì¡°ê±´]
{constraints if constraints else "ì—†ìŒ"}

ìš”ì²­: ì¸ì§€ì‹¬ë¦¬í•™ ì—°êµ¬ ì£¼ì œ {n}ê°œë¥¼ 'ë˜ì ¸ì¤˜'. ë‹¨ìˆœ ì•„ì´ë””ì–´ê°€ ì•„ë‹ˆë¼, ë°”ë¡œ ì°©ìˆ˜ ê°€ëŠ¥í•œ ìˆ˜ì¤€ìœ¼ë¡œ.
ê° ì£¼ì œë§ˆë‹¤ ì•„ë˜ í¬ë§·ì„ ë°˜ë“œì‹œ ì§€ì¼œë¼:

- ì œëª©(ì§§ê²Œ)
- í•µì‹¬ ì§ˆë¬¸ 1ë¬¸ì¥
- ê°€ì„¤ 2ê°œ(ê²€ì¦ê°€ëŠ¥)
- ìµœì†Œ ì‹¤í—˜/ë¶„ì„ ë””ìì¸(í‘œë³¸, ê³¼ì œ, ì¡°ì‘/ì¸¡ì •, ë¶„ì„)
- í•„ìš”í•œ ë¦¬ì†ŒìŠ¤(ë„êµ¬/ìê·¹/ë°ì´í„°)
- ì‹¤íŒ¨ ê°€ëŠ¥ ì§€ì  & í”ŒëœB
- 7ì¼ ì‹¤í–‰ TODO(ì²´í¬ë¦¬ìŠ¤íŠ¸)
- (ì„ íƒ) ê´€ë ¨ í‚¤ì›Œë“œ(ë…¼ë¬¸ ê²€ìƒ‰ìš©) 5ê°œ
"""
    return [
        {"role": "system", "content": SYSTEM_CORE},
        {"role": "user", "content": _clean_text(u)},
    ]

def build_paper_summary_prompt(paper: Dict[str, Any], user_goal: str) -> List[Dict[str, str]]:
    title = paper.get("title", "")
    abstract = paper.get("abstract", "")
    meta = {
        "source": paper.get("source"),
        "year": paper.get("year"),
        "publicationDate": paper.get("publicationDate"),
        "venue": paper.get("venue"),
        "citationCount": paper.get("citationCount"),
        "authors": (paper.get("authors") or [])[:6],
        "url": paper.get("url"),
        "openAccessPdf": paper.get("openAccessPdf"),
    }
    u = f"""
[ì‚¬ìš©ì ëª©í‘œ]
{user_goal.strip() if user_goal.strip() else "ì¸ì§€ì‹¬ë¦¬í•™ì—ì„œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì—°êµ¬ ì•„ì´ë””ì–´ ë°œêµ´"}

[ë…¼ë¬¸ ë©”íƒ€]
{json.dumps(meta, ensure_ascii=False)}

[ì œëª©]
{title}

[ì´ˆë¡]
{abstract if abstract else "(ì´ˆë¡ ì—†ìŒ â€” ì œëª©/ë©”íƒ€ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì •í•˜ë˜, ë¶ˆí™•ì‹¤ì„± ëª…ì‹œ)"}

ìš”ì²­: ì´ ë…¼ë¬¸ì„ 'ì—°êµ¬ ì‹¤í–‰ ê´€ì 'ì—ì„œ ìš”ì•½í•´ë¼.
ë°˜ë“œì‹œ í¬í•¨:
1) í•œ ì¤„ ìš”ì•½
2) ì—°êµ¬ ì§ˆë¬¸/ê°€ì„¤(ì¶”ì • ê°€ëŠ¥í•˜ë‚˜ ê·¼ê±°/ë¶ˆí™•ì‹¤ì„± í‘œê¸°)
3) ë°©ë²•(ê³¼ì œ/ì¸¡ì •/ë¶„ì„) í•µì‹¬
4) ê²°ê³¼/ê¸°ì—¬(ì´ˆë¡ ê¸°ë°˜)
5) ì¬í˜„/í™•ì¥ ì•„ì´ë””ì–´ 3ê°œ(ê°ê°: ì¡°ì‘, ì¸¡ì •, ì˜ˆìƒíš¨ê³¼)
6) ë‚´ê°€ ì§€ê¸ˆ ë‹¹ì¥ í•  ìˆ˜ ìˆëŠ” ë‹¤ìŒ í–‰ë™ 5ê°œ(ê²€ìƒ‰ì–´/ë°ì´í„°/ì½”ë“œ/ì‹¤í—˜)
í˜•ì‹: ë²ˆí˜¸ ì„¹ì…˜ + ë¶ˆë¦¿, í•œêµ­ì–´, ê°„ê²°.
"""
    return [
        {"role": "system", "content": SYSTEM_CORE},
        {"role": "user", "content": _clean_text(u)},
    ]

def build_idea_expansion_prompt(
    seed: str,
    papers_context: List[Dict[str, Any]],
    desired_output: str,
) -> List[Dict[str, str]]:
    # Provide compact context (titles + 1-liners if available)
    ctx_lines = []
    for p in papers_context[:6]:
        t = p.get("title", "")
        s = ""
        if p.get("llm_summary"):
            # take first line
            s = p["llm_summary"].splitlines()[0][:180]
        ctx_lines.append(f"- {t} :: {s}".strip())
    ctx = "\n".join(ctx_lines) if ctx_lines else "(ì°¸ê³  ë…¼ë¬¸ ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ)"

    u = f"""
[ì”¨ë“œ ì•„ì´ë””ì–´/ë¬¸ì œì˜ì‹]
{seed.strip()}

[ì°¸ê³  ë…¼ë¬¸ ì»¨í…ìŠ¤íŠ¸(ì œëª©+ìš”ì•½ í•œì¤„)]
{ctx}

[ì›í•˜ëŠ” ê²°ê³¼ë¬¼]
{desired_output.strip()}

ìš”ì²­: ìœ„ ì”¨ë“œë¥¼ 'ì—°êµ¬ ê³„íš'ìœ¼ë¡œ ë°œì „ì‹œì¼œë¼.
ë°˜ë“œì‹œ í¬í•¨:
A) ë©”ì»¤ë‹ˆì¦˜/êµ¬ì„±ê°œë… ì •ì˜(ì‘ë™ ê°€ì •)
B) í…ŒìŠ¤íŠ¸ ê°€ëŠ¥í•œ ê°€ì„¤ 3~5ê°œ(ê°ê°: ì¡°ì‘/ì¸¡ì •/ê¸°ëŒ€ë°©í–¥)
C) ìµœì†Œ ì‹¤í—˜ 1ê°œ + í™•ì¥ ì‹¤í—˜ 1ê°œ(ê°ê°: ë””ìì¸, í‘œë³¸, ìê·¹, ì ˆì°¨, í’ˆì§ˆê´€ë¦¬)
D) ë¶„ì„ ê³„íš(ëª¨ë¸/ê²€ì •, ì£¼ìš” DV/IV, ì‚¬ì „ ê¸°ì¤€)
E) íŒŒì›Œ/í‘œë³¸ í¬ê¸° ì‚°ì •ì— í•„ìš”í•œ ì •ë³´(ì¶”ì •ì¹˜/ê°€ì •)
F) ìœ¤ë¦¬/í¸í–¥/êµë€ìš”ì¸ ì²´í¬
G) 7ì¼ ì‹¤í–‰ í”Œëœ(ë°ì¼ë¦¬ TODO)
H) ë…¼ë¬¸ ê²€ìƒ‰ ì¿¼ë¦¬ 5ê°œ(ì˜ë¬¸)
í˜•ì‹: ì„¹ì…˜ í—¤ë” + ë¶ˆë¦¿, í•œêµ­ì–´, ê°„ê²°.
"""
    return [
        {"role": "system", "content": SYSTEM_CORE},
        {"role": "user", "content": _clean_text(u)},
    ]


# -----------------------------
# UI helpers
# -----------------------------
def render_paper_card(p: Dict[str, Any], idx: int, allow_actions: bool = True) -> None:
    title = p.get("title", "(ì œëª© ì—†ìŒ)")
    authors = ", ".join(p.get("authors") or []) if p.get("authors") else "ì €ì ì •ë³´ ì—†ìŒ"
    year = p.get("year") or ""
    venue = p.get("venue") or ""
    src = p.get("source") or ""
    cites = p.get("citationCount")
    url = p.get("url")
    pdf = p.get("openAccessPdf")

    badges = []
    if src: badges.append(f"<span class='badge'>{src}</span>")
    if year: badges.append(f"<span class='badge'>{year}</span>")
    if venue: badges.append(f"<span class='badge'>{venue}</span>")
    if cites is not None: badges.append(f"<span class='badge'>cites: {cites}</span>")
    if p.get("isOpenAccess"): badges.append("<span class='badge'>OpenAccess</span>")

    st.markdown("<div class='card'>", unsafe_allow_html=True)
    st.markdown(f"**{idx+1}. {title}**")
    st.markdown("".join(badges), unsafe_allow_html=True)
    st.markdown(f"<div class='small-muted'>Authors: {authors}</div>", unsafe_allow_html=True)

    abs_txt = (p.get("abstract") or "").strip()
    if abs_txt:
        st.write(textwrap.shorten(abs_txt, width=450, placeholder=" â€¦"))
    else:
        st.markdown("<span class='small-muted'>ì´ˆë¡ ì—†ìŒ</span>", unsafe_allow_html=True)

    cols = st.columns([1, 1, 1, 1, 2])
    if url:
        cols[0].link_button("ì›ë¬¸", url, use_container_width=True)
    else:
        cols[0].button("ì›ë¬¸", disabled=True, use_container_width=True)
    if pdf:
        cols[1].link_button("PDF", pdf, use_container_width=True)
    else:
        cols[1].button("PDF", disabled=True, use_container_width=True)

    if allow_actions:
        if cols[2].button("â­ ì¦ê²¨ì°¾ê¸°", key=f"fav_p_{p.get('id')}_{idx}", use_container_width=True):
            add_favorite_paper(p)
            st.toast("ì¦ê²¨ì°¾ê¸°ì— ì¶”ê°€ë¨", icon="â­")

        if cols[3].button("ìš”ì•½", key=f"sum_p_{p.get('id')}_{idx}", use_container_width=True):
            st.session_state["selected_paper_id"] = p.get("id")
            st.session_state["active_tab"] = "ì¸ê¸° ë…¼ë¬¸"

    st.markdown("</div>", unsafe_allow_html=True)

def add_favorite_topic(topic: Dict[str, Any]) -> None:
    store = st.session_state["store_obj"]
    fav = store.setdefault("favorites", {}).setdefault("topics", [])
    # dedupe by id
    if not any(x.get("id") == topic.get("id") for x in fav):
        fav.append(topic)
        store["updated_at"] = _now_iso()
        st.session_state["store_obj"] = store

def add_favorite_paper(paper: Dict[str, Any]) -> None:
    store = st.session_state["store_obj"]
    fav = store.setdefault("favorites", {}).setdefault("papers", [])
    if not any(x.get("id") == paper.get("id") for x in fav):
        fav.append(paper)
        store["updated_at"] = _now_iso()
        st.session_state["store_obj"] = store

def upsert_paper_in_store(paper: Dict[str, Any]) -> None:
    store = st.session_state["store_obj"]
    papers = store.setdefault("papers", [])
    pid = paper.get("id")
    for i, p in enumerate(papers):
        if p.get("id") == pid:
            papers[i] = paper
            store["updated_at"] = _now_iso()
            st.session_state["store_obj"] = store
            return
    papers.append(paper)
    store["updated_at"] = _now_iso()
    st.session_state["store_obj"] = store

def upsert_topic_in_store(topic: Dict[str, Any]) -> None:
    store = st.session_state["store_obj"]
    topics = store.setdefault("topics", [])
    tid = topic.get("id")
    for i, t in enumerate(topics):
        if t.get("id") == tid:
            topics[i] = topic
            store["updated_at"] = _now_iso()
            st.session_state["store_obj"] = store
            return
    topics.append(topic)
    store["updated_at"] = _now_iso()
    st.session_state["store_obj"] = store


# -----------------------------
# Sidebar: settings
# -----------------------------
st.sidebar.title("ğŸ§  CogCompass ì„¤ì •")

api_key = st.sidebar.text_input("OpenAI API Key", type="password", help="LLM ìš”ì•½/ì•„ì´ë””ì–´ í™•ì¥ ê¸°ëŠ¥ì— í•„ìš”í•©ë‹ˆë‹¤.")
model = st.sidebar.selectbox(
    "ëª¨ë¸",
    options=["gpt-4o-mini", "gpt-4.1-mini", "gpt-4o", "gpt-4.1"],
    index=0,
    help="ê³„ì •ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”.",
)

use_local = st.sidebar.toggle("ë¡œì»¬ ì €ì¥ ì‚¬ìš©", value=False, help="ONì´ë©´ ë¡œì»¬ JSON íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤. OFFë©´ session_stateë§Œ ì‚¬ìš©.")
store_path = st.sidebar.text_input("ë¡œì»¬ ì €ì¥ ê²½ë¡œ", value=DEFAULT_STORE_PATH, disabled=not use_local)

st.sidebar.markdown("---")
st.sidebar.caption("ì² í•™: â€˜ì—°êµ¬ ì£¼ì œ ë˜ì§€ê¸° â†’ ì¸ê¸° ë…¼ë¬¸ ìš”ì•½ â†’ ìƒê° ë°œì „ â†’ ë‹¤ìŒ 7ì¼ ì‹¤í–‰â€™ê¹Œì§€ í•œ ë²ˆì—.")

# Load store
_store = ensure_store_schema(load_store(use_local, store_path))
st.session_state["store_obj"] = _store  # working copy


# -----------------------------
# Header
# -----------------------------
left, right = st.columns([3, 2])
with left:
    st.title("CogCompass: AI ì—°êµ¬ ë„¤ë¹„ê²Œì´í„°")
    st.markdown("<div class='small-muted'>ì¸ì§€ì‹¬ë¦¬í•™ ì—°êµ¬ë¥¼ â€˜ë°”ë¡œ ì‹¤í–‰â€™ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë˜ì ¸ì£¼ëŠ” ì•±</div>", unsafe_allow_html=True)

with right:
    st.markdown("<div class='card'>", unsafe_allow_html=True)
    st.markdown("**ì˜¤ëŠ˜ì˜ ì›Œí¬í”Œë¡œìš°**")
    st.markdown(
        "- â‘  **ì£¼ì œ ë˜ì§€ê¸°**: ë°”ë¡œ ì°©ìˆ˜ ê°€ëŠ¥í•œ ì—°êµ¬ì•ˆ ìƒì„±\n"
        "- â‘¡ **ì¸ê¸° ë…¼ë¬¸**: ìµœì‹ /ì¸ê¸° ë…¼ë¬¸ ìˆ˜ì§‘ â†’ ì‹¤í–‰ ê´€ì  ìš”ì•½\n"
        "- â‘¢ **ìƒê° ë°œì „**: ì”¨ë“œ + ë…¼ë¬¸ ì»¨í…ìŠ¤íŠ¸ë¡œ ì—°êµ¬ê³„íš ì™„ì„±"
    )
    st.markdown("</div>", unsafe_allow_html=True)

# Persist changes button
persist_col1, persist_col2, persist_col3 = st.columns([1, 1, 2])
with persist_col1:
    if st.button("ğŸ’¾ ì €ì¥", use_container_width=True):
        save_store(use_local, store_path, st.session_state["store_obj"])
        st.toast("ì €ì¥ ì™„ë£Œ", icon="ğŸ’¾")
with persist_col2:
    if st.button("ğŸ§¹ ì´ˆê¸°í™”", use_container_width=True):
        st.session_state["store_obj"] = ensure_store_schema({})
        save_store(use_local, store_path, st.session_state["store_obj"])
        st.toast("ì €ì¥ì†Œ ì´ˆê¸°í™”", icon="ğŸ§¹")

with persist_col3:
    st.markdown(
        f"<div class='small-muted'>ì €ì¥ ë°©ì‹: <b>{'ë¡œì»¬ JSON' if use_local else 'ì„¸ì…˜(session_state)'}</b> Â· "
        f"ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {st.session_state['store_obj'].get('updated_at','-')}</div>",
        unsafe_allow_html=True,
    )

st.markdown("---")


# -----------------------------
# Tabs
# -----------------------------
tab_names = ["ì£¼ì œ ë˜ì§€ê¸°", "ì¸ê¸° ë…¼ë¬¸", "ìƒê° ë°œì „", "ë¼ì´ë¸ŒëŸ¬ë¦¬(ì €ì¥ë¨)"]
default_tab = st.session_state.get("active_tab", "ì£¼ì œ ë˜ì§€ê¸°")
tab_index = tab_names.index(default_tab) if default_tab in tab_names else 0
tabs = st.tabs(tab_names)
# Note: Streamlit tabs don't support programmatic switching reliably; we emulate via session_state flags.

# -----------------------------
# Tab 1: Topic Generator
# -----------------------------
with tabs[0]:
    st.subheader("ì£¼ì œ ë˜ì§€ê¸°: â€˜ë°”ë¡œ ì‹œì‘ ê°€ëŠ¥í•œâ€™ ì—°êµ¬ì•ˆ ìƒì„±")

    c1, c2, c3 = st.columns([2, 2, 1])
    with c1:
        user_context = st.text_area(
            "ë‚´ ìƒí™©/ë§¥ë½ (ì„ íƒ)",
            placeholder="ì˜ˆ: ì„ì‚¬ 1ë…„ì°¨, ì˜¨ë¼ì¸ ì‹¤í—˜ë§Œ ê°€ëŠ¥, ì‹œì„ ì¶”ì  ì—†ìŒ, í‘œë³¸ 80ëª… ì •ë„...",
            height=120,
        )
        focus = st.text_input(
            "ê´€ì‹¬ ì´ˆì ",
            value="ì£¼ì˜(attention)ì™€ ì‘ì—…ê¸°ì–µ(working memory)ì˜ ìƒí˜¸ì‘ìš©",
            help="í•œ ë¬¸ì¥ìœ¼ë¡œ ì ì„ìˆ˜ë¡ ì¢‹ìŠµë‹ˆë‹¤.",
        )
    with c2:
        methods = st.multiselect(
            "ì„ í˜¸ ë°©ë²•ë¡ /ë°ì´í„°",
            options=["ì˜¨ë¼ì¸ í–‰ë™ì‹¤í—˜", "ì‹¤í—˜ì‹¤ í–‰ë™ì‹¤í—˜", "ì„¤ë¬¸/ì²™ë„", "EEG/ERP", "fMRI", "ì•ˆêµ¬ì¶”ì ", "ê³„ì‚°ëª¨ë¸/ì‹œë®¬ë ˆì´ì…˜", "ë©”íƒ€ë¶„ì„", "ê¸°ì¡´ ê³µê°œë°ì´í„° ì¬ë¶„ì„"],
            default=["ì˜¨ë¼ì¸ í–‰ë™ì‹¤í—˜"],
        )
        constraints = st.text_area(
            "ì œì•½/í˜„ì‹¤ ì¡°ê±´ (ì„ íƒ)",
            placeholder="ì˜ˆ: 2ì£¼ ë‚´ íŒŒì¼ëŸ¿ í•„ìš”, ìê·¹ ì œì‘ ìµœì†Œí™”, í•œêµ­ì–´ ê³¼ì œ ì„ í˜¸, ì°¸ê°€ì ë¹„ìš© ì œí•œ...",
            height=120,
        )
    with c3:
        n_topics = st.number_input("ìƒì„± ê°œìˆ˜", min_value=3, max_value=10, value=5, step=1)
        temperature = st.slider("ì°½ì˜ì„±(temperature)", min_value=0.0, max_value=1.0, value=0.5, step=0.05)

        generate_btn = st.button("ğŸ§  ì—°êµ¬ ì£¼ì œ ë˜ì ¸ì¤˜", use_container_width=True)

    if generate_btn:
        if not api_key:
            st.error("OpenAI API Keyë¥¼ ì‚¬ì´ë“œë°”ì— ì…ë ¥í•˜ì„¸ìš”.")
        else:
            with st.spinner("ì—°êµ¬ ì£¼ì œ ìƒì„± ì¤‘..."):
                messages = build_topic_prompt(user_context, focus, methods, constraints, int(n_topics))
                try:
                    out = openai_chat_completion(
                        api_key=api_key,
                        model=model,
                        messages=messages,
                        temperature=float(temperature),
                        max_tokens=1400,
                    )
                except Exception as e:
                    st.error(str(e))
                    out = ""

            if out:
                topic_obj = {
                    "id": str(uuid.uuid4()),
                    "created_at": _now_iso(),
                    "focus": focus,
                    "methods": methods,
                    "constraints": constraints,
                    "user_context": user_context,
                    "llm_output": out,
                }
                upsert_topic_in_store(topic_obj)
                save_store(use_local, store_path, st.session_state["store_obj"])

                st.markdown("### ê²°ê³¼")
                st.markdown(out)

                colA, colB = st.columns([1, 1])
                if colA.button("â­ ì´ ê²°ê³¼ ì¦ê²¨ì°¾ê¸°", use_container_width=True):
                    add_favorite_topic(topic_obj)
                    save_store(use_local, store_path, st.session_state["store_obj"])
                    st.toast("ì¦ê²¨ì°¾ê¸°ì— ì¶”ê°€ë¨", icon="â­")
                if colB.button("â¡ï¸ ìƒê° ë°œì „ìœ¼ë¡œ ê°€ì ¸ê°€ê¸°", use_container_width=True):
                    st.session_state["seed_idea"] = out
                    st.session_state["active_tab"] = "ìƒê° ë°œì „"
                    st.success("ì”¨ë“œë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤. ìƒë‹¨ì˜ â€˜ìƒê° ë°œì „â€™ íƒ­ìœ¼ë¡œ ì´ë™í•´ ê³„ì† ì§„í–‰í•˜ì„¸ìš”.")

    # Recent topics
    st.markdown("---")
    st.markdown("#### ìµœê·¼ ìƒì„±í•œ ì£¼ì œ")
    recent_topics = list(reversed(st.session_state["store_obj"].get("topics", [])))[0:5]
    if not recent_topics:
        st.markdown("<div class='small-muted'>ì•„ì§ ìƒì„± ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.</div>", unsafe_allow_html=True)
    else:
        for t in recent_topics:
            with st.expander(f"ğŸ§© {t.get('focus','(no focus)')} Â· {t.get('created_at','')}", expanded=False):
                st.markdown(t.get("llm_output", ""))
                c1, c2, c3 = st.columns([1, 1, 2])
                if c1.button("â­ ì¦ê²¨ì°¾ê¸°", key=f"fav_topic_{t.get('id')}", use_container_width=True):
                    add_favorite_topic(t)
                    save_store(use_local, store_path, st.session_state["store_obj"])
                    st.toast("ì¦ê²¨ì°¾ê¸°ì— ì¶”ê°€ë¨", icon="â­")
                if c2.button("â¡ï¸ ì”¨ë“œë¡œ ì‚¬ìš©", key=f"use_seed_{t.get('id')}", use_container_width=True):
                    st.session_state["seed_idea"] = t.get("llm_output", "")
                    st.session_state["active_tab"] = "ìƒê° ë°œì „"
                    st.success("ì”¨ë“œë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤. â€˜ìƒê° ë°œì „â€™ íƒ­ì—ì„œ ì´ì–´ê°€ì„¸ìš”.")
                st.caption(f"Methods: {', '.join(t.get('methods') or [])}")


# -----------------------------
# Tab 2: Trending Papers + Summaries
# -----------------------------
with tabs[1]:
    st.subheader("ì¸ê¸° ë…¼ë¬¸: ìˆ˜ì§‘ â†’ ì‹¤í–‰ ê´€ì  ìš”ì•½ â†’ ì•„ì´ë””ì–´ë¡œ ì—°ê²°")

    c1, c2, c3, c4 = st.columns([2, 1, 1, 1])
    with c1:
        paper_query = st.text_input(
            "ê²€ìƒ‰ í‚¤ì›Œë“œ(ì˜ë¬¸ ê¶Œì¥)",
            value="attention working memory cognitive control",
            help="Semantic Scholar/arXivì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤. (ì˜ˆ: 'visual attention suppression', 'task switching' ë“±)",
        )
        user_goal = st.text_input("ìš”ì•½ì„ ì–´ë–¤ ëª©ì ì— ë§ì¶œê¹Œ?", value="2ì£¼ ë‚´ ì˜¨ë¼ì¸ í–‰ë™ì‹¤í—˜ìœ¼ë¡œ í™•ì¥ ê°€ëŠ¥í•œ ì•„ì´ë””ì–´ ì°¾ê¸°")
    with c2:
        source_choice = st.selectbox("ì†ŒìŠ¤", ["Semantic Scholar", "arXiv", "ë‘˜ ë‹¤"], index=0)
        sort_choice = st.selectbox("ì •ë ¬(SS)", ["citationCount", "publicationDate"], index=0)
    with c3:
        year_from = st.number_input("From(ì—°ë„)", min_value=1990, max_value=2100, value=2022, step=1)
        year_to = st.number_input("To(ì—°ë„)", min_value=1990, max_value=2100, value=2026, step=1)
    with c4:
        k = st.number_input("ê°€ì ¸ì˜¬ ê°œìˆ˜", min_value=5, max_value=20, value=10, step=1)
        fetch_btn = st.button("ğŸ” ë…¼ë¬¸ ê°€ì ¸ì˜¤ê¸°", use_container_width=True)

    papers: List[Dict[str, Any]] = []
    if fetch_btn:
        with st.spinner("ë…¼ë¬¸ ìˆ˜ì§‘ ì¤‘..."):
            if source_choice in ("Semantic Scholar", "ë‘˜ ë‹¤"):
                ss = fetch_semantic_scholar_papers(
                    paper_query,
                    limit=int(k),
                    year_from=int(year_from) if year_from else None,
                    year_to=int(year_to) if year_to else None,
                    sort=sort_choice,
                )
                papers.extend(ss)
            if source_choice in ("arXiv", "ë‘˜ ë‹¤"):
                ax = fetch_arxiv_papers(paper_query, limit=int(k))
                papers.extend(ax)

        # assign internal ids and store
        normalized = []
        for p in papers:
            pid = p.get("paperId") or p.get("url") or (p.get("title","") + "_" + (p.get("publicationDate") or ""))
            p2 = dict(p)
            p2["id"] = str(uuid.uuid5(uuid.NAMESPACE_URL, str(pid)))
            p2.setdefault("fetched_at", _now_iso())
            normalized.append(p2)

        st.session_state["last_fetched_papers"] = normalized

        # upsert into store (without LLM summary yet)
        for p in normalized:
            upsert_paper_in_store(p)
        save_store(use_local, store_path, st.session_state["store_obj"])
        st.toast(f"{len(normalized)}ê°œ ì €ì¥ë¨", icon="ğŸ“š")

    # Display last fetched
    st.markdown("---")
    fetched = st.session_state.get("last_fetched_papers", [])
    if not fetched:
        st.markdown("<div class='small-muted'>ì•„ì§ ìˆ˜ì§‘ëœ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤. ìœ„ì—ì„œ ê²€ìƒ‰í•´ë³´ì„¸ìš”.</div>", unsafe_allow_html=True)
    else:
        st.markdown("### ìˆ˜ì§‘ëœ ë…¼ë¬¸")
        for i, p in enumerate(fetched):
            render_paper_card(p, i, allow_actions=True)

    st.markdown("---")
    st.markdown("### ì„ íƒ ë…¼ë¬¸ ì‹¤í–‰ ê´€ì  ìš”ì•½")

    selected_id = st.session_state.get("selected_paper_id")
    store_papers = st.session_state["store_obj"].get("papers", [])
    selected = next((p for p in store_papers if p.get("id") == selected_id), None) if selected_id else None

    if not selected:
        st.markdown("<div class='small-muted'>ë…¼ë¬¸ ì¹´ë“œì—ì„œ <b>ìš”ì•½</b>ì„ ëˆŒëŸ¬ ì„ íƒí•˜ì„¸ìš”.</div>", unsafe_allow_html=True)
    else:
        st.markdown(f"**ì„ íƒë¨:** {selected.get('title','')}")
        do_sum = st.button("ğŸ§¾ LLM ìš”ì•½ ìƒì„±/ê°±ì‹ ", use_container_width=True)

        if do_sum:
            if not api_key:
                st.error("OpenAI API Keyë¥¼ ì‚¬ì´ë“œë°”ì— ì…ë ¥í•˜ì„¸ìš”.")
            else:
                with st.spinner("ìš”ì•½ ìƒì„± ì¤‘..."):
                    messages = build_paper_summary_prompt(selected, user_goal)
                    try:
                        summary = openai_chat_completion(
                            api_key=api_key,
                            model=model,
                            messages=messages,
                            temperature=0.3,
                            max_tokens=1100,
                        )
                    except Exception as e:
                        st.error(str(e))
                        summary = ""

                if summary:
                    selected["llm_summary"] = summary
                    selected["summary_updated_at"] = _now_iso()
                    upsert_paper_in_store(selected)
                    save_store(use_local, store_path, st.session_state["store_obj"])
                    st.toast("ìš”ì•½ ì €ì¥ ì™„ë£Œ", icon="âœ…")

        if selected.get("llm_summary"):
            st.markdown(selected["llm_summary"])
            c1, c2 = st.columns([1, 1])
            if c1.button("â¡ï¸ ìƒê° ë°œì „ì— ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©", use_container_width=True):
                st.session_state["selected_papers_for_expansion"] = [selected.get("id")]
                st.session_state["active_tab"] = "ìƒê° ë°œì „"
                st.success("ì„ íƒ ë…¼ë¬¸ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤. â€˜ìƒê° ë°œì „â€™ íƒ­ì—ì„œ ì´ì–´ê°€ì„¸ìš”.")
            if c2.button("â­ ì¦ê²¨ì°¾ê¸°", use_container_width=True):
                add_favorite_paper(selected)
                save_store(use_local, store_path, st.session_state["store_obj"])
                st.toast("ì¦ê²¨ì°¾ê¸°ì— ì¶”ê°€ë¨", icon="â­")
        else:
            st.markdown("<div class='small-muted'>ì•„ì§ ìš”ì•½ì´ ì—†ìŠµë‹ˆë‹¤. ìœ„ ë²„íŠ¼ìœ¼ë¡œ ìƒì„±í•˜ì„¸ìš”.</div>", unsafe_allow_html=True)


# -----------------------------
# Tab 3: Idea Expansion
# -----------------------------
with tabs[2]:
    st.subheader("ìƒê° ë°œì „: ì”¨ë“œ + ë…¼ë¬¸ ì»¨í…ìŠ¤íŠ¸ â†’ ì—°êµ¬ê³„íš & 7ì¼ í”Œëœ")

    # Pick seed
    seed_default = st.session_state.get("seed_idea", "")
    seed = st.text_area(
        "ì”¨ë“œ ì•„ì´ë””ì–´ / ë¬¸ì œì˜ì‹",
        value=seed_default,
        placeholder="ì£¼ì œ ë˜ì§€ê¸° ê²°ê³¼ ì¼ë¶€ë¥¼ ë¶™ì—¬ë„£ê±°ë‚˜, ë‹¹ì‹ ì˜ ì•„ì´ë””ì–´ë¥¼ ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”.",
        height=220,
    )

    # Select papers context
    st.markdown("#### ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©í•  ë…¼ë¬¸ ì„ íƒ (ì €ì¥ëœ ë…¼ë¬¸ ì¤‘)")
    store_papers = st.session_state["store_obj"].get("papers", [])
    paper_options = []
    for p in store_papers:
        label = f"{p.get('title','(no title)')[:80]}"
        paper_options.append((label, p.get("id")))

    preselected = st.session_state.get("selected_papers_for_expansion", [])
    selected_ids = st.multiselect(
        "ë…¼ë¬¸ ì„ íƒ (ìµœëŒ€ 6ê°œ ê¶Œì¥)",
        options=[pid for _, pid in paper_options],
        default=[pid for pid in preselected if pid in [x[1] for x in paper_options]],
        format_func=lambda pid: next((lbl for lbl, _pid in paper_options if _pid == pid), pid),
    )

    desired_output = st.text_input(
        "ì›í•˜ëŠ” ê²°ê³¼ë¬¼ í˜•íƒœ(ì„ íƒ)",
        value="ì˜¨ë¼ì¸ í–‰ë™ì‹¤í—˜ 1ê°œ + í™•ì¥ ì‹¤í—˜ 1ê°œê°€ í¬í•¨ëœ ì—°êµ¬ ê³„íšì„œ",
    )

    c1, c2, c3 = st.columns([1, 1, 2])
    with c1:
        temp2 = st.slider("ì •êµí•¨(temperature)", min_value=0.0, max_value=1.0, value=0.35, step=0.05)
    with c2:
        run_btn = st.button("ğŸ§­ ê³„íšìœ¼ë¡œ ë°œì „ì‹œí‚¤ê¸°", use_container_width=True)
    with c3:
        st.markdown("<div class='small-muted'>íŒ: â€˜ì”¨ë“œâ€™ë¥¼ ì§§ê²Œ ì“°ì§€ ë§ê³ , ì´ë¯¸ ê°€ì§„ ê°€ì •/ì œì•½/ëª©í‘œë¥¼ ê°™ì´ ì ìœ¼ë©´ í’ˆì§ˆì´ í¬ê²Œ ì˜¬ë¼ê°‘ë‹ˆë‹¤.</div>", unsafe_allow_html=True)

    if run_btn:
        if not api_key:
            st.error("OpenAI API Keyë¥¼ ì‚¬ì´ë“œë°”ì— ì…ë ¥í•˜ì„¸ìš”.")
        elif not seed.strip():
            st.error("ì”¨ë“œ ì•„ì´ë””ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            # Build context papers
            ctx_papers = []
            for pid in selected_ids[:6]:
                p = next((x for x in store_papers if x.get("id") == pid), None)
                if p:
                    ctx_papers.append(p)

            with st.spinner("ì—°êµ¬ê³„íš ìƒì„± ì¤‘..."):
                messages = build_idea_expansion_prompt(seed, ctx_papers, desired_output)
                try:
                    plan = openai_chat_completion(
                        api_key=api_key,
                        model=model,
                        messages=messages,
                        temperature=float(temp2),
                        max_tokens=1600,
                    )
                except Exception as e:
                    st.error(str(e))
                    plan = ""

            if plan:
                note = {
                    "id": str(uuid.uuid4()),
                    "created_at": _now_iso(),
                    "type": "expanded_plan",
                    "seed": seed,
                    "paper_ids": selected_ids[:6],
                    "output": plan,
                }
                store = st.session_state["store_obj"]
                store.setdefault("notes", []).append(note)
                store["updated_at"] = _now_iso()
                st.session_state["store_obj"] = store
                save_store(use_local, store_path, st.session_state["store_obj"])
                st.toast("ê³„íš ì €ì¥ ì™„ë£Œ", icon="âœ…")

                st.markdown("### ê²°ê³¼: ì—°êµ¬ê³„íš")
                st.markdown(plan)

                cA, cB = st.columns([1, 1])
                if cA.button("ğŸ“Œ ì”¨ë“œë¡œ ì¬ì‚¬ìš©", use_container_width=True):
                    st.session_state["seed_idea"] = plan
                    st.toast("ê²°ê³¼ë¥¼ ì”¨ë“œë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.", icon="ğŸ“Œ")
                if cB.button("ğŸ’¾ ì €ì¥", use_container_width=True):
                    save_store(use_local, store_path, st.session_state["store_obj"])
                    st.toast("ì €ì¥ ì™„ë£Œ", icon="ğŸ’¾")


# -----------------------------
# Tab 4: Library
# -----------------------------
with tabs[3]:
    st.subheader("ë¼ì´ë¸ŒëŸ¬ë¦¬(ì €ì¥ë¨): ì£¼ì œ / ë…¼ë¬¸ / í”Œëœ / ì¦ê²¨ì°¾ê¸°")

    store = st.session_state["store_obj"]
    c1, c2, c3, c4 = st.columns([1, 1, 1, 1])
    c1.metric("ì£¼ì œ", len(store.get("topics", [])))
    c2.metric("ë…¼ë¬¸", len(store.get("papers", [])))
    c3.metric("ë…¸íŠ¸/í”Œëœ", len(store.get("notes", [])))
    fav_count = len(store.get("favorites", {}).get("topics", [])) + len(store.get("favorites", {}).get("papers", []))
    c4.metric("ì¦ê²¨ì°¾ê¸°", fav_count)

    st.markdown("---")

    colL, colR = st.columns([1, 1])

    with colL:
        st.markdown("### â­ ì¦ê²¨ì°¾ê¸°: ì£¼ì œ")
        fav_topics = store.get("favorites", {}).get("topics", [])
        if not fav_topics:
            st.markdown("<div class='small-muted'>ì¦ê²¨ì°¾ê¸°ëœ ì£¼ì œê°€ ì—†ìŠµë‹ˆë‹¤.</div>", unsafe_allow_html=True)
        else:
            for t in reversed(fav_topics[-20:]):
                with st.expander(f"â­ {t.get('focus','(no focus)')} Â· {t.get('created_at','')}", expanded=False):
                    st.markdown(t.get("llm_output", ""))

        st.markdown("### ğŸ§© ì €ì¥ëœ ì£¼ì œ")
        topics = store.get("topics", [])
        if not topics:
            st.markdown("<div class='small-muted'>ì €ì¥ëœ ì£¼ì œê°€ ì—†ìŠµë‹ˆë‹¤.</div>", unsafe_allow_html=True)
        else:
            for t in reversed(topics[-15:]):
                with st.expander(f"ğŸ§© {t.get('focus','(no focus)')} Â· {t.get('created_at','')}", expanded=False):
                    st.markdown(t.get("llm_output", ""))
                    c1, c2 = st.columns([1, 1])
                    if c1.button("â­ ì¦ê²¨ì°¾ê¸°", key=f"fav_t_lib_{t.get('id')}", use_container_width=True):
                        add_favorite_topic(t)
                        save_store(use_local, store_path, st.session_state["store_obj"])
                        st.toast("ì¦ê²¨ì°¾ê¸°ì— ì¶”ê°€ë¨", icon="â­")
                    if c2.button("â¡ï¸ ì”¨ë“œë¡œ", key=f"seed_t_lib_{t.get('id')}", use_container_width=True):
                        st.session_state["seed_idea"] = t.get("llm_output", "")
                        st.session_state["active_tab"] = "ìƒê° ë°œì „"
                        st.success("ì”¨ë“œë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤. â€˜ìƒê° ë°œì „â€™ íƒ­ì—ì„œ ì´ì–´ê°€ì„¸ìš”.")

    with colR:
        st.markdown("### â­ ì¦ê²¨ì°¾ê¸°: ë…¼ë¬¸")
        fav_papers = store.get("favorites", {}).get("papers", [])
        if not fav_papers:
            st.markdown("<div class='small-muted'>ì¦ê²¨ì°¾ê¸°ëœ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.</div>", unsafe_allow_html=True)
        else:
            for i, p in enumerate(reversed(fav_papers[-20:])):
                render_paper_card(p, i, allow_actions=False)
                if p.get("llm_summary"):
                    with st.expander("ìš”ì•½ ë³´ê¸°", expanded=False):
                        st.markdown(p["llm_summary"])

        st.markdown("### ğŸ—’ï¸ ë…¸íŠ¸/í”Œëœ")
        notes = store.get("notes", [])
        if not notes:
            st.markdown("<div class='small-muted'>ì•„ì§ ì €ì¥ëœ í”Œëœ/ë…¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.</div>", unsafe_allow_html=True)
        else:
            for n in reversed(notes[-20:]):
                title = f"ğŸ—’ï¸ {n.get('type','note')} Â· {n.get('created_at','')}"
                with st.expander(title, expanded=False):
                    st.markdown("**Seed**")
                    st.code((n.get("seed", "") or "")[:2000])
                    st.markdown("**Output**")
                    st.markdown(n.get("output", ""))


# -----------------------------
# Footer: auto-save working copy into session or file when local enabled
# -----------------------------
# We don't auto-save on every widget change to avoid excessive IO, but do a light save
# when local storage is enabled and enough time has passed.
if "last_autosave_ts" not in st.session_state:
    st.session_state["last_autosave_ts"] = 0.0

autosave_interval = 20.0  # seconds
if time.time() - st.session_state["last_autosave_ts"] > autosave_interval:
    # keep session store always, and optionally write local
    save_store(False, store_path, st.session_state["store_obj"])  # session copy
    if use_local:
        save_store(True, store_path, st.session_state["store_obj"])
    st.session_state["last_autosave_ts"] = time.time()
